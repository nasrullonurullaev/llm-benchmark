name: Vllm benchmark

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model to benchmark'
        required: true
        default: "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"  

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      GPU_TYPE: "NVIDIA RTX 2000 Ada Generation"
      IMAGE_NAME: "vllm/vllm-openai:latest"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install runpodctl
        run: wget -qO- cli.runpod.net | sudo bash

      - name: Configure runpodctl
        run: runpodctl config --apiKey ${{ secrets.API_KEY }} || ls ~/runners
        
      - name: Create RunPod pod
        run: |
          CREATE_OUTPUT=$(runpodctl create pod --ports '8000/tcp' --secureCloud --gpuType "$GPU_TYPE" --imageName "$IMAGE_NAME" --args "--model ${{ inputs.model }} --max-model-len 4096 --port 8000 --enforce-eager --gpu-memory-utilization 0.95")
          POD_ID=$(echo "$CREATE_OUTPUT" | awk -F'"' '/pod "/ {print $2}')
          echo "POD_ID=$POD_ID" >> $GITHUB_ENV

      - name: Wait for pod to be ready
        run: sleep 60         

      - name: Get RunPod pod details
        run: |
          ENDPOINT=$(echo "$(runpodctl get pod $POD_ID -a)" | grep -oP '\d+\.\d+\.\d+\.\d+:\d+(?=->8000)')
          echo "ENDPOINT=$ENDPOINT" >> $GITHUB_ENV
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
   
      - name: Clone vLLM repository
        run: |
          git clone https://github.com/vllm-project/vllm
          cd vllm
          VLLM_USE_PRECOMPILED=1 pip install --editable .

      - name: Install dependency
        run: pip install pandas datasets       
      
      - name: Install dependency
        run: pip install -U pynvml
        
      - name: Run benchmark
        run: |
          cd vllm/benchmarks
          python3 benchmark_serving.py --backend openai \
              --base-url "http://$ENDPOINT" \
              --dataset-name=random \
              --result-filename "output.json" \
              --model "${{ inputs.model }}" \
              --seed 12345

      - name: Install dependency
        run: ls -l vllm/benchmarks
        
      - name: Archive benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: vllm-results
          path: output.json
          
      - name: Remove RunPod pod
#        if: always()
        run: runpodctl remove pod $POD_ID
              
