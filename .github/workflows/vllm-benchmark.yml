name: vLLM Benchmark

on:
  workflow_dispatch:
    inputs:
      model:
        description: "Model to benchmark"
        required: true
        default: "neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8"

jobs:
  benchmark:
    name: Run vLLM Benchmark
    runs-on: ubuntu-latest
    env:
      GPU_TYPE: "NVIDIA RTX 2000 Ada Generation"
      IMAGE_NAME: "vllm/vllm-openai:latest"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Install runpodctl
        run: wget -qO- cli.runpod.net | sudo bash

      - name: Configure runpodctl
        run: runpodctl config --apiKey ${{ secrets.API_KEY }} || ls ~/runners

      - name: Create RunPod Instance
        run: |
          CREATE_OUTPUT=$(runpodctl create pod \
            --ports "8000/tcp" \
            --secureCloud \
            --gpuType "$GPU_TYPE" \
            --imageName "$IMAGE_NAME" \
            --args "--model ${{ inputs.model }} --max-model-len 4096 --port 8000 --enforce-eager --gpu-memory-utilization 0.95")
          POD_ID=$(echo "$CREATE_OUTPUT" | awk -F'"' '/pod "/ {print $2}')
          echo "POD_ID=$POD_ID" >> $GITHUB_ENV

      - name: Wait for Pod to Be Ready
        run: sleep 60

      - name: Retrieve RunPod Endpoint
        run: |
          ENDPOINT=$(echo "$(runpodctl get pod $POD_ID -a)" | grep -oP '\d+\.\d+\.\d+\.\d+:\d+(?=->8000)')
          echo "ENDPOINT=$ENDPOINT" >> $GITHUB_ENV

      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Clone vLLM Repository
        run: |
          git clone https://github.com/vllm-project/vllm
          cd vllm
          VLLM_USE_PRECOMPILED=1 pip install --editable .

      - name: Install Dependencies
        run: pip install pandas datasets pynvml

      - name: Run Benchmark
        run: |
          cd vllm/benchmarks
          python3 benchmark_serving.py --backend openai \
              --base-url "http://$ENDPOINT" \
              --dataset-name=random \
              --model "${{ inputs.model }}" \
              --result-filename "benchmark_result.json" \
              --save-result \
              --seed 12345

      - name: Install Dependencies
        run: ls

      - name: Install Dependencies
        run: ls vllm/benchmarks

      - name: Archive Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: vllm/benchmarks/benchmark_result.json        


      - name: Remove RunPod Instance
        if: always()
        run: runpodctl remove pod $POD_ID
